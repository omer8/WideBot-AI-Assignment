{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                 Classification On The Hespress News Dataset\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:828/0*-MNlm46aQfTjdCpp\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omar mohamed\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\Users\\omar mohamed\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold,train_test_split,cross_validate,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier,plot_tree\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,confusion_matrix,classification_report\n",
    "import warnings\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('archive\\stories_faits-divers.csv')\n",
    "df2= pd.read_csv('archive\\stories_art-et-culture.csv')\n",
    "df3= pd.read_csv('archive\\stories_regions.csv')\n",
    "df4= pd.read_csv('archive\\stories_sport.csv')\n",
    "df5= pd.read_csv('archive\\stories_medias.csv')\n",
    "df6= pd.read_csv('archive\\stories_economie.csv')\n",
    "df7= pd.read_csv('archive\\stories_tamazight.csv')\n",
    "df8= pd.read_csv('archive\\stories_societe.csv')\n",
    "df9= pd.read_csv('archive\\stories_orbites.csv')\n",
    "df10= pd.read_csv('archive\\stories_politique.csv')\n",
    "df11= pd.read_csv('archive\\stories_marocains-du-monde.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatunate data\n",
    "df = df.append([df2,df3,df4,df5,df6,df7,df8,df9,df10,df11],ignore_index=True).drop(['Unnamed: 0','id'],axis=1).sample(frac = 1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining Title and Story Columns\n",
    "df['story'] = df['title']+' '+df['story']\n",
    "df.drop(columns='title',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>story</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الثلاثاء 19 نونبر 2019 - 22:00</td>\n",
       "      <td>هسبريس ـ فاطمة الزهراء صدور</td>\n",
       "      <td>رصيف الصحافة: موجة إعفاءات تعصف بأطر وزارة الت...</td>\n",
       "      <td>medias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>السبت 22 غشت 2020 - 23:00</td>\n",
       "      <td>إبراهيم مغراوي من مراكش</td>\n",
       "      <td>إغلاق متجرَين بعد اقتحام الفيروس أسوار \"مرجان\"...</td>\n",
       "      <td>regions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الأربعاء 08 ماي 2019 - 22:00</td>\n",
       "      <td>هسبريس ـ فاطمة الزهراء صدور</td>\n",
       "      <td>رصيف الصحافة: الجزائر تخصص تعويضا شهريا لمقرّب...</td>\n",
       "      <td>medias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>السبت 14 يناير 2017 - 15:00</td>\n",
       "      <td>هسبريس - محمد الراجي</td>\n",
       "      <td>العنصر: خريطة الفقر في المملكة تنطبق على مناطق...</td>\n",
       "      <td>tamazight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الجمعة 28 غشت 2020 - 09:00</td>\n",
       "      <td>هسبريس - نورالدين إكجان</td>\n",
       "      <td>\"الفيروس\" يتمدد في المغرب .. \"كورونا\" يقتحم مد...</td>\n",
       "      <td>regions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date                       author  \\\n",
       "0  الثلاثاء 19 نونبر 2019 - 22:00  هسبريس ـ فاطمة الزهراء صدور   \n",
       "1       السبت 22 غشت 2020 - 23:00      إبراهيم مغراوي من مراكش   \n",
       "2    الأربعاء 08 ماي 2019 - 22:00  هسبريس ـ فاطمة الزهراء صدور   \n",
       "3     السبت 14 يناير 2017 - 15:00         هسبريس - محمد الراجي   \n",
       "4      الجمعة 28 غشت 2020 - 09:00      هسبريس - نورالدين إكجان   \n",
       "\n",
       "                                               story      topic  \n",
       "0  رصيف الصحافة: موجة إعفاءات تعصف بأطر وزارة الت...     medias  \n",
       "1  إغلاق متجرَين بعد اقتحام الفيروس أسوار \"مرجان\"...    regions  \n",
       "2  رصيف الصحافة: الجزائر تخصص تعويضا شهريا لمقرّب...     medias  \n",
       "3  العنصر: خريطة الفقر في المملكة تنطبق على مناطق...  tamazight  \n",
       "4  \"الفيروس\" يتمدد في المغرب .. \"كورونا\" يقتحم مد...    regions  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicated\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10998 entries, 0 to 10999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   date    10998 non-null  object\n",
      " 1   author  10998 non-null  object\n",
      " 2   story   10998 non-null  object\n",
      " 3   topic   10998 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 429.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normalization\n",
    "* Punctuation Removal\n",
    "* Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "stops = set(stopwords.words(\"arabic\"))\n",
    "stop_word_comp = {\"،\",\"آض\",\"آمينَ\",\"آه\",\"آهاً\",\"آي\",\"أ\",\"أب\",\"أجل\",\"أجمع\",\"أخ\",\"أخذ\",\"أصبح\",\"أضحى\",\"أقبل\",\"أقل\",\"أكثر\",\"ألا\",\"أم\",\"أما\",\"أمامك\",\"أمامكَ\",\"أمسى\",\"أمّا\",\"أن\",\"أنا\",\"أنت\",\"أنتم\",\"أنتما\",\"أنتن\",\"أنتِ\",\"أنشأ\",\"أنّى\",\"أو\",\"أوشك\",\"أولئك\",\"أولئكم\",\"أولاء\",\"أولالك\",\"أوّهْ\",\"أي\",\"أيا\",\"أين\",\"أينما\",\"أيّ\",\"أَنَّ\",\"أََيُّ\",\"أُفٍّ\",\"إذ\",\"إذا\",\"إذاً\",\"إذما\",\"إذن\",\"إلى\",\"إليكم\",\"إليكما\",\"إليكنّ\",\"إليكَ\",\"إلَيْكَ\",\"إلّا\",\"إمّا\",\"إن\",\"إنّما\",\"إي\",\"إياك\",\"إياكم\",\"إياكما\",\"إياكن\",\"إيانا\",\"إياه\",\"إياها\",\"إياهم\",\"إياهما\",\"إياهن\",\"إياي\",\"إيهٍ\",\"إِنَّ\",\"ا\",\"ابتدأ\",\"اثر\",\"اجل\",\"احد\",\"اخرى\",\"اخلولق\",\"اذا\",\"اربعة\",\"ارتدّ\",\"استحال\",\"اطار\",\"اعادة\",\"اعلنت\",\"اف\",\"اكثر\",\"اكد\",\"الألاء\",\"الألى\",\"الا\",\"الاخيرة\",\"الان\",\"الاول\",\"الاولى\",\"التى\",\"التي\",\"الثاني\",\"الثانية\",\"الذاتي\",\"الذى\",\"الذي\",\"الذين\",\"السابق\",\"الف\",\"اللائي\",\"اللاتي\",\"اللتان\",\"اللتيا\",\"اللتين\",\"اللذان\",\"اللذين\",\"اللواتي\",\"الماضي\",\"المقبل\",\"الوقت\",\"الى\",\"اليوم\",\"اما\",\"امام\",\"امس\",\"ان\",\"انبرى\",\"انقلب\",\"انه\",\"انها\",\"او\",\"اول\",\"اي\",\"ايار\",\"ايام\",\"ايضا\",\"ب\",\"بات\",\"باسم\",\"بان\",\"بخٍ\",\"برس\",\"بسبب\",\"بسّ\",\"بشكل\",\"بضع\",\"بطآن\",\"بعد\",\"بعض\",\"بك\",\"بكم\",\"بكما\",\"بكن\",\"بل\",\"بلى\",\"بما\",\"بماذا\",\"بمن\",\"بن\",\"بنا\",\"به\",\"بها\",\"بي\",\"بيد\",\"بين\",\"بَسْ\",\"بَلْهَ\",\"بِئْسَ\",\"تانِ\",\"تانِك\",\"تبدّل\",\"تجاه\",\"تحوّل\",\"تلقاء\",\"تلك\",\"تلكم\",\"تلكما\",\"تم\",\"تينك\",\"تَيْنِ\",\"تِه\",\"تِي\",\"ثلاثة\",\"ثم\",\"ثمّ\",\"ثمّة\",\"ثُمَّ\",\"جعل\",\"جلل\",\"جميع\",\"جير\",\"حار\",\"حاشا\",\"حاليا\",\"حاي\",\"حتى\",\"حرى\",\"حسب\",\"حم\",\"حوالى\",\"حول\",\"حيث\",\"حيثما\",\"حين\",\"حيَّ\",\"حَبَّذَا\",\"حَتَّى\",\"حَذارِ\",\"خلا\",\"خلال\",\"دون\",\"دونك\",\"ذا\",\"ذات\",\"ذاك\",\"ذانك\",\"ذانِ\",\"ذلك\",\"ذلكم\",\"ذلكما\",\"ذلكن\",\"ذو\",\"ذوا\",\"ذواتا\",\"ذواتي\",\"ذيت\",\"ذينك\",\"ذَيْنِ\",\"ذِه\",\"ذِي\",\"راح\",\"رجع\",\"رويدك\",\"ريث\",\"رُبَّ\",\"زيارة\",\"سبحان\",\"سرعان\",\"سنة\",\"سنوات\",\"سوف\",\"سوى\",\"سَاءَ\",\"سَاءَمَا\",\"شبه\",\"شخصا\",\"شرع\",\"شَتَّانَ\",\"صار\",\"صباح\",\"صفر\",\"صهٍ\",\"صهْ\",\"ضد\",\"ضمن\",\"طاق\",\"طالما\",\"طفق\",\"طَق\",\"ظلّ\",\"عاد\",\"عام\",\"عاما\",\"عامة\",\"عدا\",\"عدة\",\"عدد\",\"عدم\",\"عسى\",\"عشر\",\"عشرة\",\"علق\",\"على\",\"عليك\",\"عليه\",\"عليها\",\"علًّ\",\"عن\",\"عند\",\"عندما\",\"عوض\",\"عين\",\"عَدَسْ\",\"عَمَّا\",\"غدا\",\"غير\",\"ـ\",\"ف\",\"فان\",\"فلان\",\"فو\",\"فى\",\"في\",\"فيم\",\"فيما\",\"فيه\",\"فيها\",\"قال\",\"قام\",\"قبل\",\"قد\",\"قطّ\",\"قلما\",\"قوة\",\"كأنّما\",\"كأين\",\"كأيّ\",\"كأيّن\",\"كاد\",\"كان\",\"كانت\",\"كذا\",\"كذلك\",\"كرب\",\"كل\",\"كلا\",\"كلاهما\",\"كلتا\",\"كلم\",\"كليكما\",\"كليهما\",\"كلّما\",\"كلَّا\",\"كم\",\"كما\",\"كي\",\"كيت\",\"كيف\",\"كيفما\",\"كَأَنَّ\",\"كِخ\",\"لئن\",\"لا\",\"لات\",\"لاسيما\",\"لدن\",\"لدى\",\"لعمر\",\"لقاء\",\"لك\",\"لكم\",\"لكما\",\"لكن\",\"لكنَّما\",\"لكي\",\"لكيلا\",\"للامم\",\"لم\",\"لما\",\"لمّا\",\"لن\",\"لنا\",\"له\",\"لها\",\"لو\",\"لوكالة\",\"لولا\",\"لوما\",\"لي\",\"لَسْتَ\",\"لَسْتُ\",\"لَسْتُم\",\"لَسْتُمَا\",\"لَسْتُنَّ\",\"لَسْتِ\",\"لَسْنَ\",\"لَعَلَّ\",\"لَكِنَّ\",\"لَيْتَ\",\"لَيْسَ\",\"لَيْسَا\",\"لَيْسَتَا\",\"لَيْسَتْ\",\"لَيْسُوا\",\"لَِسْنَا\",\"ما\",\"ماانفك\",\"مابرح\",\"مادام\",\"ماذا\",\"مازال\",\"مافتئ\",\"مايو\",\"متى\",\"مثل\",\"مذ\",\"مساء\",\"مع\",\"معاذ\",\"مقابل\",\"مكانكم\",\"مكانكما\",\"مكانكنّ\",\"مكانَك\",\"مليار\",\"مليون\",\"مما\",\"ممن\",\"من\",\"منذ\",\"منها\",\"مه\",\"مهما\",\"مَنْ\",\"مِن\",\"نحن\",\"نحو\",\"نعم\",\"نفس\",\"نفسه\",\"نهاية\",\"نَخْ\",\"نِعِمّا\",\"نِعْمَ\",\"ها\",\"هاؤم\",\"هاكَ\",\"هاهنا\",\"هبّ\",\"هذا\",\"هذه\",\"هكذا\",\"هل\",\"هلمَّ\",\"هلّا\",\"هم\",\"هما\",\"هن\",\"هنا\",\"هناك\",\"هنالك\",\"هو\",\"هي\",\"هيا\",\"هيت\",\"هيّا\",\"هَؤلاء\",\"هَاتانِ\",\"هَاتَيْنِ\",\"هَاتِه\",\"هَاتِي\",\"هَجْ\",\"هَذا\",\"هَذانِ\",\"هَذَيْنِ\",\"هَذِه\",\"هَذِي\",\"هَيْهَاتَ\",\"و\",\"و6\",\"وا\",\"واحد\",\"واضاف\",\"واضافت\",\"واكد\",\"وان\",\"واهاً\",\"واوضح\",\"وراءَك\",\"وفي\",\"وقال\",\"وقالت\",\"وقد\",\"وقف\",\"وكان\",\"وكانت\",\"ولا\",\"ولم\",\"ومن\",\"مَن\",\"وهو\",\"وهي\",\"ويكأنّ\",\"وَيْ\",\"وُشْكَانََ\",\"يكون\",\"يمكن\",\"يوم\",\"ّأيّان\"}\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    zen = TextBlob(text)\n",
    "    words = zen.words\n",
    "    return \" \".join([w for w in words if not w in stops and not w in stop_word_comp and len(w) >= 2])\n",
    "\n",
    "\n",
    "df['story'] = df['story'].apply(lambda x:normalize_arabic(x))\n",
    "df['story'] = df['story'].apply(lambda x:remove_punctuations(x))\n",
    "df['story'] = df['story'].apply(lambda x:remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>story</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الثلاثاء 19 نونبر 2019 - 22:00</td>\n",
       "      <td>هسبريس ـ فاطمة الزهراء صدور</td>\n",
       "      <td>رصيف الصحافه موجه اعفاءات تعصف باطر وزاره التر...</td>\n",
       "      <td>medias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>السبت 22 غشت 2020 - 23:00</td>\n",
       "      <td>إبراهيم مغراوي من مراكش</td>\n",
       "      <td>اغلاق متجرَين اقتحام الفيروس اسوار مرجان اغلقت...</td>\n",
       "      <td>regions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الأربعاء 08 ماي 2019 - 22:00</td>\n",
       "      <td>هسبريس ـ فاطمة الزهراء صدور</td>\n",
       "      <td>رصيف الصحافه الجزاءر تخصص تعويضا شهريا لمقرّب ...</td>\n",
       "      <td>medias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>السبت 14 يناير 2017 - 15:00</td>\n",
       "      <td>هسبريس - محمد الراجي</td>\n",
       "      <td>العنصر خريطه الفقر المملكه تنطبق علي مناطق يقط...</td>\n",
       "      <td>tamazight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الجمعة 28 غشت 2020 - 09:00</td>\n",
       "      <td>هسبريس - نورالدين إكجان</td>\n",
       "      <td>الفيروس يتمدد المغرب كورونا يقتحم مدن وقري الج...</td>\n",
       "      <td>regions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date                       author  \\\n",
       "0  الثلاثاء 19 نونبر 2019 - 22:00  هسبريس ـ فاطمة الزهراء صدور   \n",
       "1       السبت 22 غشت 2020 - 23:00      إبراهيم مغراوي من مراكش   \n",
       "2    الأربعاء 08 ماي 2019 - 22:00  هسبريس ـ فاطمة الزهراء صدور   \n",
       "3     السبت 14 يناير 2017 - 15:00         هسبريس - محمد الراجي   \n",
       "4      الجمعة 28 غشت 2020 - 09:00      هسبريس - نورالدين إكجان   \n",
       "\n",
       "                                               story      topic  \n",
       "0  رصيف الصحافه موجه اعفاءات تعصف باطر وزاره التر...     medias  \n",
       "1  اغلاق متجرَين اقتحام الفيروس اسوار مرجان اغلقت...    regions  \n",
       "2  رصيف الصحافه الجزاءر تخصص تعويضا شهريا لمقرّب ...     medias  \n",
       "3  العنصر خريطه الفقر المملكه تنطبق علي مناطق يقط...  tamazight  \n",
       "4  الفيروس يتمدد المغرب كورونا يقتحم مدن وقري الج...    regions  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preper Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = LabelEncoder()\n",
    "df.topic = en.fit_transform(df.topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spliting the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['story']\n",
    "y = df['topic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(model, X_train, y_train):\n",
    "    ac = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "        tokenizer = nltk.word_tokenize, \n",
    "        analyzer = \"word\")),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', model),\n",
    "    ])\n",
    "    ac.fit(X_train, y_train)\n",
    "    return ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Logistic Regression***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accurcy:-->  0.954421459422596\n",
      "Testing Accurcy:-->  0.86\n"
     ]
    }
   ],
   "source": [
    "logit = model(LogisticRegression(), X_train, y_train)\n",
    "print(\"Training Accurcy:--> \" , accuracy_score(y_train,logit.predict(X_train)))\n",
    "print(\"Testing Accurcy:--> \" , accuracy_score(y_test,logit.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       178\n",
      "           1       0.83      0.87      0.85       207\n",
      "           2       0.94      0.94      0.94       196\n",
      "           3       0.87      0.89      0.88       205\n",
      "           4       0.97      0.89      0.93       209\n",
      "           5       0.73      0.77      0.75       200\n",
      "           6       0.77      0.77      0.77       222\n",
      "           7       0.85      0.80      0.82       211\n",
      "           8       0.72      0.74      0.73       189\n",
      "           9       1.00      0.98      0.99       170\n",
      "          10       0.98      0.92      0.95       213\n",
      "\n",
      "    accuracy                           0.86      2200\n",
      "   macro avg       0.86      0.86      0.86      2200\n",
      "weighted avg       0.86      0.86      0.86      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,logit.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SVM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accurcy:-->  0.9961354853375767\n",
      "Testing Accurcy:-->  0.855\n"
     ]
    }
   ],
   "source": [
    "svm = model(SVC(), X_train, y_train)\n",
    "print(\"Training Accurcy:--> \" , accuracy_score(y_train,svm.predict(X_train)))\n",
    "print(\"Testing Accurcy:--> \" , accuracy_score(y_test,svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       178\n",
      "           1       0.84      0.86      0.85       207\n",
      "           2       0.94      0.93      0.94       196\n",
      "           3       0.91      0.89      0.90       205\n",
      "           4       0.98      0.87      0.92       209\n",
      "           5       0.67      0.79      0.72       200\n",
      "           6       0.77      0.75      0.76       222\n",
      "           7       0.85      0.77      0.81       211\n",
      "           8       0.70      0.77      0.73       189\n",
      "           9       1.00      0.96      0.98       170\n",
      "          10       0.98      0.92      0.95       213\n",
      "\n",
      "    accuracy                           0.85      2200\n",
      "   macro avg       0.86      0.86      0.86      2200\n",
      "weighted avg       0.86      0.85      0.86      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Random Forest Classifier***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accurcy:-->  1.0\n",
      "Testing Accurcy:-->  0.8095454545454546\n"
     ]
    }
   ],
   "source": [
    "rfor = model(RandomForestClassifier(), X_train, y_train)\n",
    "print(\"Training Accurcy:--> \" , accuracy_score(y_train,rfor.predict(X_train)))\n",
    "print(\"Testing Accurcy:--> \" , accuracy_score(y_test,rfor.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       178\n",
      "           1       0.73      0.88      0.80       207\n",
      "           2       0.81      0.96      0.88       196\n",
      "           3       0.85      0.80      0.82       205\n",
      "           4       0.97      0.83      0.90       209\n",
      "           5       0.76      0.56      0.64       200\n",
      "           6       0.68      0.78      0.73       222\n",
      "           7       0.77      0.73      0.75       211\n",
      "           8       0.75      0.59      0.66       189\n",
      "           9       0.97      0.99      0.98       170\n",
      "          10       0.94      0.89      0.91       213\n",
      "\n",
      "    accuracy                           0.81      2200\n",
      "   macro avg       0.82      0.81      0.81      2200\n",
      "weighted avg       0.81      0.81      0.81      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,rfor.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***XGBoost***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accurcy:-->  1.0\n",
      "Testing Accurcy:-->  0.825\n"
     ]
    }
   ],
   "source": [
    "xgb = model(XGBClassifier(), X_train, y_train)\n",
    "print(\"Training Accurcy:--> \" , accuracy_score(y_train,xgb.predict(X_train)))\n",
    "print(\"Testing Accurcy:--> \" , accuracy_score(y_test,xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86       178\n",
      "           1       0.77      0.82      0.79       207\n",
      "           2       0.91      0.92      0.91       196\n",
      "           3       0.82      0.84      0.83       205\n",
      "           4       0.95      0.89      0.92       209\n",
      "           5       0.65      0.61      0.63       200\n",
      "           6       0.75      0.77      0.76       222\n",
      "           7       0.79      0.74      0.77       211\n",
      "           8       0.69      0.72      0.70       189\n",
      "           9       0.98      0.95      0.96       170\n",
      "          10       0.95      0.97      0.96       213\n",
      "\n",
      "    accuracy                           0.82      2200\n",
      "   macro avg       0.83      0.83      0.83      2200\n",
      "weighted avg       0.83      0.82      0.83      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LightGBM***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accurcy:-->  1.0\n",
      "Testing Accurcy:-->  0.8345454545454546\n"
     ]
    }
   ],
   "source": [
    "lgb = model(LGBMClassifier(), X_train, y_train)\n",
    "print(\"Training Accurcy:--> \" , accuracy_score(y_train,lgb.predict(X_train)))\n",
    "print(\"Testing Accurcy:--> \" , accuracy_score(y_test,lgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       178\n",
      "           1       0.79      0.85      0.82       207\n",
      "           2       0.91      0.93      0.92       196\n",
      "           3       0.81      0.84      0.83       205\n",
      "           4       0.95      0.88      0.91       209\n",
      "           5       0.67      0.67      0.67       200\n",
      "           6       0.76      0.75      0.75       222\n",
      "           7       0.83      0.78      0.80       211\n",
      "           8       0.75      0.74      0.74       189\n",
      "           9       0.96      0.95      0.96       170\n",
      "          10       0.95      0.95      0.95       213\n",
      "\n",
      "    accuracy                           0.83      2200\n",
      "   macro avg       0.84      0.84      0.84      2200\n",
      "weighted avg       0.84      0.83      0.83      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,lgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7f174_row0_col0 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7f174_row1_col0 {\n",
       "  background-color: #191919;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7f174_row2_col0 {\n",
       "  background-color: #818181;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7f174_row3_col0 {\n",
       "  background-color: #b1b1b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7f174_row4_col0 {\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7f174_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7f174_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_7f174_row0_col0\" class=\"data row0 col0\" >0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f174_level0_row1\" class=\"row_heading level0 row1\" >SVC</th>\n",
       "      <td id=\"T_7f174_row1_col0\" class=\"data row1 col0\" >0.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f174_level0_row2\" class=\"row_heading level0 row2\" >LGBMClassifier</th>\n",
       "      <td id=\"T_7f174_row2_col0\" class=\"data row2 col0\" >0.834545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f174_level0_row3\" class=\"row_heading level0 row3\" >XGBClassifier</th>\n",
       "      <td id=\"T_7f174_row3_col0\" class=\"data row3 col0\" >0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f174_level0_row4\" class=\"row_heading level0 row4\" >RForest</th>\n",
       "      <td id=\"T_7f174_row4_col0\" class=\"data row4 col0\" >0.809545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e6c567bd68>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score = pd.Series(accuracy_score(y_test,logit.predict(X_test)))\n",
    "svc_score = pd.Series(accuracy_score(y_test,svm.predict(X_test)))\n",
    "rfor_score = pd.Series(accuracy_score(y_test,rfor.predict(X_test)))\n",
    "xgb_score = pd.Series(accuracy_score(y_test,xgb.predict(X_test)))\n",
    "lgb_score = pd.Series(accuracy_score(y_test,lgb.predict(X_test)))\n",
    "\n",
    "\n",
    "models_score= pd.DataFrame(index=['LogisticRegression','SVC','RForest','XGBClassifier','LGBMClassifier'],\n",
    "                        data= [log_score,svc_score,rfor_score,xgb_score,lgb_score]).rename(columns={0:'accuracy'}).sort_values('accuracy',ascending=False)\n",
    "models_score.style.background_gradient(cmap='binary')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
